{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata  = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64\n",
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "\n",
    "    return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=40):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "    return tf.py_function(encode, [pt, en], [tf.int64, tf.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([8214 1259    5   63 5284   50  277    2 8215    0], shape=(10,), dtype=int64)\n",
      "tf.Tensor([8087   18   12  631   15   31  272    2 8088    0], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(pt_batch[0, :10])\n",
    "print(en_batch[0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 4\n",
    "d_model = 128\n",
    "d_ff = 512\n",
    "n_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "output_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    \"\"\"\n",
    "    sparse categorical crossentropy, masking out padded words\n",
    "    \"\"\"\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    \n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207723, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(tf.convert_to_tensor([1, 1, 2]), \n",
    "              tf.convert_to_tensor([\n",
    "                  [0.0, 99.0, 0.0],\n",
    "                  [0.0, 99.0, 0.0],\n",
    "                  [0.0, 0.0, 99.0]\n",
    "              ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207747, shape=(), dtype=float32, numpy=0.7324082>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(tf.convert_to_tensor([1, 1, 0]), \n",
    "              tf.convert_to_tensor([\n",
    "                  [0.0, 0.0, 0.0],\n",
    "                  [0.0, 0.0, 0.0],\n",
    "                  [99.0, 0.0, 0.0]\n",
    "              ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(input_vocab_size, output_vocab_size, d_model, n_layers, n_heads, d_ff, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "def create_look_ahead_mask(sequence_length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sequence_length: the length of input sequence\n",
    "    Returns:\n",
    "        look_ahead_mask: shape (sequence_length, sequence_length)\n",
    "        \n",
    "    e.g\n",
    "    sequence_lenght = 3\n",
    "    look_ahead_mask = [\n",
    "        [0, 1, 1], on predicting the 1st word, only the 0th word (the <START/> token) will be used\n",
    "        [0, 0, 1], on predicting the 2nd word, only the 1st word and the 0th word can be used\n",
    "        [0, 0, 0]  and so on\n",
    "    ]\n",
    "    \"\"\"\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((sequence_length, sequence_length)), -1, 0)\n",
    "    return look_ahead_mask\n",
    "\n",
    "def create_padding_mask(sparse_input_sequence):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sparse_input_sequence: shape(batch_size, sequence_length) e.g [0, 1, 3, 0, 5, 13]\n",
    "    Returns:\n",
    "        padding_mask: boolean mask where 1s indicates padding. e.g [1, 0, 0, 1, 0, 0] for the example input\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(sparse_input_sequence, 0), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = transformer(inp, tar_inp, \n",
    "                                     True, \n",
    "                                     enc_padding_mask, \n",
    "                                     combined_mask, \n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.4134 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 3.4729 Accuracy 0.0239\n",
      "Epoch 1 Batch 100 Loss 3.2400 Accuracy 0.0344\n",
      "Epoch 1 Batch 150 Loss 3.1261 Accuracy 0.0444\n",
      "Epoch 1 Batch 200 Loss 3.0323 Accuracy 0.0537\n",
      "Epoch 1 Batch 250 Loss 2.9512 Accuracy 0.0622\n",
      "Epoch 1 Batch 300 Loss 2.8769 Accuracy 0.0693\n",
      "Epoch 1 Batch 350 Loss 2.8184 Accuracy 0.0754\n",
      "Epoch 1 Batch 400 Loss 2.7647 Accuracy 0.0803\n",
      "Epoch 1 Batch 450 Loss 2.7194 Accuracy 0.0846\n",
      "Epoch 1 Batch 500 Loss 2.6828 Accuracy 0.0885\n",
      "Epoch 1 Batch 550 Loss 2.6508 Accuracy 0.0920\n",
      "Epoch 1 Batch 600 Loss 2.6213 Accuracy 0.0951\n",
      "Epoch 1 Batch 650 Loss 2.5933 Accuracy 0.0981\n",
      "Epoch 1 Batch 700 Loss 2.5690 Accuracy 0.1005\n",
      "Epoch 1 Loss 2.5676 Accuracy 0.1006\n",
      "Time taken for 1 epoch: 135.47014904022217 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.0592 Accuracy 0.1367\n",
      "Epoch 2 Batch 50 Loss 2.2168 Accuracy 0.1366\n",
      "Epoch 2 Batch 100 Loss 2.2062 Accuracy 0.1376\n",
      "Epoch 2 Batch 150 Loss 2.2007 Accuracy 0.1385\n",
      "Epoch 2 Batch 200 Loss 2.1904 Accuracy 0.1389\n",
      "Epoch 2 Batch 250 Loss 2.1811 Accuracy 0.1397\n",
      "Epoch 2 Batch 300 Loss 2.1835 Accuracy 0.1410\n",
      "Epoch 2 Batch 350 Loss 2.1722 Accuracy 0.1416\n",
      "Epoch 2 Batch 400 Loss 2.1623 Accuracy 0.1422\n",
      "Epoch 2 Batch 450 Loss 2.1539 Accuracy 0.1433\n",
      "Epoch 2 Batch 500 Loss 2.1506 Accuracy 0.1442\n",
      "Epoch 2 Batch 550 Loss 2.1439 Accuracy 0.1449\n",
      "Epoch 2 Batch 600 Loss 2.1351 Accuracy 0.1454\n",
      "Epoch 2 Batch 650 Loss 2.1300 Accuracy 0.1461\n",
      "Epoch 2 Batch 700 Loss 2.1227 Accuracy 0.1468\n",
      "Epoch 2 Loss 2.1225 Accuracy 0.1468\n",
      "Time taken for 1 epoch: 92.18661832809448 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.1588 Accuracy 0.1659\n",
      "Epoch 3 Batch 50 Loss 1.9955 Accuracy 0.1597\n",
      "Epoch 3 Batch 100 Loss 1.9950 Accuracy 0.1601\n",
      "Epoch 3 Batch 150 Loss 1.9923 Accuracy 0.1601\n",
      "Epoch 3 Batch 200 Loss 1.9950 Accuracy 0.1610\n",
      "Epoch 3 Batch 250 Loss 1.9902 Accuracy 0.1616\n",
      "Epoch 3 Batch 300 Loss 1.9910 Accuracy 0.1625\n",
      "Epoch 3 Batch 350 Loss 1.9833 Accuracy 0.1629\n",
      "Epoch 3 Batch 400 Loss 1.9786 Accuracy 0.1635\n",
      "Epoch 3 Batch 450 Loss 1.9723 Accuracy 0.1644\n",
      "Epoch 3 Batch 500 Loss 1.9676 Accuracy 0.1651\n",
      "Epoch 3 Batch 550 Loss 1.9620 Accuracy 0.1657\n",
      "Epoch 3 Batch 600 Loss 1.9566 Accuracy 0.1661\n",
      "Epoch 3 Batch 650 Loss 1.9504 Accuracy 0.1666\n",
      "Epoch 3 Batch 700 Loss 1.9451 Accuracy 0.1672\n",
      "Saved checkpoint for step: checkpoints/ckpt-1\n",
      "Epoch 3 Loss 1.9451 Accuracy 0.1672\n",
      "Time taken for 1 epoch: 92.92586708068848 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.8744 Accuracy 0.1719\n",
      "Epoch 4 Batch 50 Loss 1.8208 Accuracy 0.1808\n",
      "Epoch 4 Batch 100 Loss 1.8137 Accuracy 0.1812\n",
      "Epoch 4 Batch 150 Loss 1.8072 Accuracy 0.1805\n",
      "Epoch 4 Batch 200 Loss 1.8169 Accuracy 0.1810\n",
      "Epoch 4 Batch 250 Loss 1.8084 Accuracy 0.1808\n",
      "Epoch 4 Batch 300 Loss 1.8052 Accuracy 0.1814\n",
      "Epoch 4 Batch 350 Loss 1.8072 Accuracy 0.1824\n",
      "Epoch 4 Batch 400 Loss 1.8024 Accuracy 0.1832\n",
      "Epoch 4 Batch 450 Loss 1.7942 Accuracy 0.1836\n",
      "Epoch 4 Batch 500 Loss 1.7900 Accuracy 0.1839\n",
      "Epoch 4 Batch 550 Loss 1.7866 Accuracy 0.1846\n",
      "Epoch 4 Batch 600 Loss 1.7803 Accuracy 0.1852\n",
      "Epoch 4 Batch 650 Loss 1.7774 Accuracy 0.1859\n",
      "Epoch 4 Batch 700 Loss 1.7730 Accuracy 0.1868\n",
      "Epoch 4 Loss 1.7736 Accuracy 0.1868\n",
      "Time taken for 1 epoch: 92.27720069885254 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.4540 Accuracy 0.1841\n",
      "Epoch 5 Batch 50 Loss 1.6364 Accuracy 0.1998\n",
      "Epoch 5 Batch 100 Loss 1.6382 Accuracy 0.2026\n",
      "Epoch 5 Batch 150 Loss 1.6358 Accuracy 0.2030\n",
      "Epoch 5 Batch 200 Loss 1.6281 Accuracy 0.2042\n",
      "Epoch 5 Batch 250 Loss 1.6193 Accuracy 0.2050\n",
      "Epoch 5 Batch 300 Loss 1.6136 Accuracy 0.2057\n",
      "Epoch 5 Batch 350 Loss 1.6097 Accuracy 0.2058\n",
      "Epoch 5 Batch 400 Loss 1.6070 Accuracy 0.2068\n",
      "Epoch 5 Batch 450 Loss 1.6019 Accuracy 0.2075\n",
      "Epoch 5 Batch 500 Loss 1.6028 Accuracy 0.2083\n",
      "Epoch 5 Batch 550 Loss 1.5994 Accuracy 0.2088\n",
      "Epoch 5 Batch 600 Loss 1.5984 Accuracy 0.2095\n",
      "Epoch 5 Batch 650 Loss 1.5936 Accuracy 0.2099\n",
      "Epoch 5 Batch 700 Loss 1.5904 Accuracy 0.2103\n",
      "Epoch 5 Loss 1.5902 Accuracy 0.2104\n",
      "Time taken for 1 epoch: 92.19751214981079 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    # inp -> portuguese, tar -> english\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "\n",
    "    if (epoch + 1) % 3 == 0:\n",
    "        save_path = ckpt_manager.save()\n",
    "        print(\"Saved checkpoint for step: {}\".format(save_path))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [tokenizer_pt.vocab_size]\n",
    "    end_token = [tokenizer_pt.vocab_size + 1]\n",
    "\n",
    "    # inp sentence is portuguese, hence adding the start and end token\n",
    "    inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    # as the target is english, the first word to the transformer should be the\n",
    "    # english start token.\n",
    "    decoder_input = [tokenizer_en.vocab_size]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(40):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions = transformer(encoder_input, \n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == tokenizer_en.vocab_size+1:\n",
    "            return tf.squeeze(output, axis=0)\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result = evaluate(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é um problema que temos que resolver.\n",
      "Predicted translation: this is a problem that we have to do in the universe .\n",
      "Real translation: this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_position_encoding(sequence_length, d_embedding):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sequence_length: the length of input sequence. \n",
    "            d_embedding: the dimension of the embedding space. i.e \n",
    "        Returns:\n",
    "            positional_encoding: shape (1, sequence_length, d_embedding)\n",
    "            Note: the output is unsequeeze at dimension 1 to enable easier broadcasting\n",
    "        \"\"\"\n",
    "\n",
    "        # position[i] = the i-th index the sequence\n",
    "        positions = tf.range(sequence_length, dtype=tf.float32)[:, tf.newaxis]\n",
    "        # embedding_indices[i] = the i-th index in the embedding \n",
    "        # Note: embedding_indices has length d_embedding/2, because sin and cos share the same input\n",
    "        # e.g [0, 2, 4, 6] for d_embedding = 8\n",
    "        embedding_indices = tf.range(d_embedding, delta=2, dtype=tf.float32)[tf.newaxis:]\n",
    "\n",
    "        # inner = pos/10000^(2i/EmbeddingDimension), i.e the input to sin and cos\n",
    "        inner = positions / 10000**(embedding_indices/tf.cast(d_embedding, tf.float32))\n",
    "        sin_position_encodings = tf.math.sin(inner)\n",
    "        cos_position_encodings = tf.math.cos(inner)\n",
    "        # to create alternating sin and cos encodings, we use a hack: we expand dim at the last axis and concatenate the resulting tensors\n",
    "        sin_position_encodings = tf.expand_dims(sin_position_encodings, axis=-1)\n",
    "        cos_position_encodings = tf.expand_dims(cos_position_encodings, axis=-1)\n",
    "        position_encodings = tf.concat([sin_position_encodings, cos_position_encodings], axis=-1)\n",
    "        position_encodings = tf.reshape(position_encodings, (1, sequence_length, d_embedding))\n",
    "        return position_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
